# ФИО, Группа

Титеев Александр Максимович, М8О-308Б-17
# Датасеты

Первый и второй датасеты лежат в папке dataset и dataset2  соответственно. После работы с ними получилось два датасета: Education.csv, netflix.csv. Код с помощью которых они получились и графики можно посмотреть в Lab1.1.ipynb Lab1.2.ipynb.

# Алгоритмы
Было реализованно 4 алгоритма:

    "Случайный лес" — алгоритм машинного обучения, предложенный Лео Брейманом и Адель Катлер, заключающийся в использовании комитета (ансамбля) решающих деревьев. Случайный лес, как и следует из его названия, состоит из большого количества отдельных деревьев решений, которые работают как ансамбль методов. Каждое дерево в случайном лесу возвращает прогноз класса, и класс с наибольшим количеством голосов становится прогнозом леса.
    KNN. Для классификации каждого из объектов тестовой выборки необходимо последовательно выполнить несколько операций. Вычислить расстояние до каждого из объектов обучающей выборки. Затем отобрать k объектов обучающей выборки, расстояние до которых минимально. При решении задачи регрессии нужно взять их среднее значение, для задачи классфикации наиболее часто встречающиеся.
    Решающее дерево — это объединение логических правил вида "Значение признака a меньше x И Значение признака b меньше y… => Класс 1" в структуру данных "Дерево"
    Логистическая регрессия — это статистическая модель, используемая для прогнозирования вероятности возникновения некоторого события путём его сравнения с логистической кривой.

Их реализацию и применение можно посмотреть в Lab2.ipynb.

# Выводы

Работать с данными оказалось труднее чем я изначально думал, но все возникшие трудности были вполне решаемы. Также было выявленно много подводных камней при работе с numpy, которые сильно влияют на производительность, однако моё владение им всё ещё недостаточно, т.к. мои реализации значительно уступают в скорости реализации от sklearn. В целом эти лабораторные работы помогли лучше понять машинное обучениие и сложности возникающие в процессе.
